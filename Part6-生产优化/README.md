# Part 6：生产优化

> 本阶段目标：理解真正跑起来需要的优化技术

## 章节列表

| 章节 | 主题 | 视频来源 | 播放量 |
|-----|------|---------|--------|
| 第21章 | Flash Attention - 内存优化原理 | P2-V7 | 2.1万 |
| 第22章 | KV Cache - 推理加速的关键 | P2-V8 | **5.5万**  |

## 学完本阶段后

你将能够：
- 理解为什么原始 Attention 在长序列上很慢
- 解释 Flash Attention 的核心优化思路
- 理解 KV Cache 如何加速自回归生成
- 针对场景选择合适的优化策略
